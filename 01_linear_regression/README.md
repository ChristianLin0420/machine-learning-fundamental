# Linear Regression

## ğŸ“Œ Overview
Implement linear regression from scratch using NumPy to understand the fundamental concepts of supervised learning.

## ğŸ§  Key Concepts
- Hypothesis: y = Wx + b
- Loss Function: Mean Squared Error (MSE)
- Optimization: Gradient Descent
- Normal Equation (closed-form solution)

## ğŸ› ï¸ Implementation
- Matrix-vector formulation
- Manual gradient computation
- Learning rate optimization
- Cost function visualization

## ğŸ“Š Results
- Fit line visualized on synthetic data
- Cost function convergence plots
- Performance metrics (RÂ², RMSE)

## ğŸ“š References
- [Andrew Ng's Machine Learning Course](https://www.coursera.org/learn/machine-learning)
- [Elements of Statistical Learning](https://hastie.su.domains/ElemStatLearn/)
- [Hands-On Machine Learning](https://github.com/ageron/handson-ml2) 