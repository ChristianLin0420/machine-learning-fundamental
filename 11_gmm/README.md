# Gaussian Mixture Models (GMM)

## 📌 Overview
Implement Gaussian Mixture Models for clustering and density estimation using probabilistic approach with multiple Gaussian distributions.

## 🧠 Key Concepts
- Mixture of Gaussians
- Maximum Likelihood Estimation
- Expectation-Maximization Algorithm
- Model Selection (AIC, BIC)

## 🛠️ Implementation
- Multivariate Gaussian probability density
- EM algorithm for parameter estimation
- Initialization strategies (K-means++, random)
- Convergence criteria and likelihood computation

## 📊 Results
- Cluster assignment probabilities
- Gaussian component visualization
- Model selection plots (AIC/BIC vs components)
- Comparison with K-means clustering

## 📚 References
- [Gaussian Mixture Models Explained](https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95)
- [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/people/cmbishop/)
- [Scikit-learn GMM Documentation](https://scikit-learn.org/stable/modules/mixture.html) 