# Gaussian Mixture Models (GMM)

## ğŸ“Œ Overview
Implement Gaussian Mixture Models for clustering and density estimation using probabilistic approach with multiple Gaussian distributions.

## ğŸ§  Key Concepts
- Mixture of Gaussians
- Maximum Likelihood Estimation
- Expectation-Maximization Algorithm
- Model Selection (AIC, BIC)

## ğŸ› ï¸ Implementation
- Multivariate Gaussian probability density
- EM algorithm for parameter estimation
- Initialization strategies (K-means++, random)
- Convergence criteria and likelihood computation

## ğŸ“Š Results
- Cluster assignment probabilities
- Gaussian component visualization
- Model selection plots (AIC/BIC vs components)
- Comparison with K-means clustering

## ğŸ“š References
- [Gaussian Mixture Models Explained](https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95)
- [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/people/cmbishop/)
- [Scikit-learn GMM Documentation](https://scikit-learn.org/stable/modules/mixture.html) 