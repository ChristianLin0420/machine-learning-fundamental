# Expectation-Maximization (EM) Algorithm

## 📌 Overview
Implement the Expectation-Maximization algorithm for parameter estimation in probabilistic models with latent variables.

## 🧠 Key Concepts
- Latent Variable Models
- Expectation Step (E-step)
- Maximization Step (M-step)
- Lower Bound on Log-Likelihood

## 🛠️ Implementation
- General EM framework
- E-step: Computing posterior probabilities
- M-step: Parameter updates
- Convergence monitoring and stopping criteria

## 📊 Results
- Log-likelihood convergence plots
- Parameter evolution during iterations
- Comparison with direct optimization methods
- Applications to various probabilistic models

## 📚 References
- [EM Algorithm Tutorial](https://towardsdatascience.com/expectation-maximization-algorithm-clearly-explained-abb17a31b820)
- [Maximum Likelihood from Incomplete Data](https://web.mit.edu/6.435/www/Dempster77.pdf)
- [Machine Learning: A Probabilistic Perspective](https://probml.github.io/pml-book/) 