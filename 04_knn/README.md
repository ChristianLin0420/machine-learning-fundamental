# K-Nearest Neighbors (KNN)

## ğŸ“Œ Overview
Implement the K-Nearest Neighbors algorithm for both classification and regression tasks using distance-based predictions.

## ğŸ§  Key Concepts
- Instance-Based Learning (Lazy Learning)
- Distance Metrics: Euclidean, Manhattan, Minkowski
- Curse of Dimensionality
- Optimal K Selection

## ğŸ› ï¸ Implementation
- Distance calculation functions
- Efficient neighbor search algorithms
- Majority voting for classification
- Weighted voting based on distance

## ğŸ“Š Results
- Decision boundaries for different K values
- Performance comparison across K values
- Computational complexity analysis
- Feature scaling impact visualization

## ğŸ“š References
- [KNN Algorithm Explained](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761)
- [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/people/cmbishop/)
- [Introduction to Data Mining](https://www-users.cs.umn.edu/~kumar001/dmbook/index.php) 