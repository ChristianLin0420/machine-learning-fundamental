# ResNet-50 Configuration for CIFAR-10
# Deep model with bottleneck blocks for maximum accuracy

# Model architecture
arch: resnet50
pre_activation: true  # Pre-activation helps with deeper networks

# Training parameters
epochs: 300  # Deeper model needs more epochs
batch_size: 128
lr: 0.1
weight_decay: 0.0005
momentum: 0.9

# Learning rate scheduling
scheduler: warmup_cosine
warmup_epochs: 10  # Longer warmup for deeper model
min_lr: 0.00001

# Regularization
mixup_alpha: 0.2
mixup_prob: 1.0
cutmix: true
label_smoothing: 0.1
grad_clip: 1.0  # Light gradient clipping for stability

# Data augmentation
randaugment: true

# Hardware
num_workers: 4
print_freq: 50
save_freq: 50

# Expected results:
# - Best validation accuracy: >95%
# - Training time: ~6-8 hours on GPU
# - Parameters: ~23M