# Naive Bayes

## 📌 Overview
Implement Naive Bayes classifier based on Bayes' theorem with the "naive" assumption of conditional independence between features.

## 🧠 Key Concepts
- Bayes' Theorem: P(A|B) = P(B|A) * P(A) / P(B)
- Conditional Independence Assumption
- Gaussian, Multinomial, and Bernoulli Naive Bayes
- Laplace Smoothing

## 🛠️ Implementation
- Prior probability calculation
- Likelihood estimation for different distributions
- Posterior probability computation
- Smoothing techniques for zero probabilities

## 📊 Results
- Classification performance on text and numerical data
- Feature importance visualization
- Comparison of different Naive Bayes variants
- Confusion matrix and classification report

## 📚 References
- [Naive Bayes Classifier Explained](https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c)
- [Machine Learning: A Probabilistic Perspective](https://probml.github.io/pml-book/)
- [Text Classification with Naive Bayes](https://web.stanford.edu/class/cs124/lec/naivebayes.pdf) 